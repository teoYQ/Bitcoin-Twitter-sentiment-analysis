{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"regdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Unnamed: 0.1', 'date2', 'hour', 'Daily Weight count',\n",
      "       'blob_sent_hourly mean', 'vader_sent_hourly mean', 'day n hour',\n",
      "       'tweet dir', 'vsent dir', 'bsent dir', 'bsent movement',\n",
      "       'tweet movement', 'vsent movement', 'vesent movement', 'Close',\n",
      "       '5hr MA', 'price dir', 'movement', 'date2.1', 'month', 'hour.1'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date2</th>\n",
       "      <th>hour</th>\n",
       "      <th>vader_sent_hourly mean</th>\n",
       "      <th>Daily Weight count</th>\n",
       "      <th>Close</th>\n",
       "      <th>price dir</th>\n",
       "      <th>movement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147142</td>\n",
       "      <td>735</td>\n",
       "      <td>3700.31</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158979</td>\n",
       "      <td>603</td>\n",
       "      <td>3689.69</td>\n",
       "      <td>3.538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.151551</td>\n",
       "      <td>629</td>\n",
       "      <td>3690.00</td>\n",
       "      <td>3.656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.183226</td>\n",
       "      <td>546</td>\n",
       "      <td>3693.13</td>\n",
       "      <td>1.340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.202897</td>\n",
       "      <td>519</td>\n",
       "      <td>3692.71</td>\n",
       "      <td>-2.038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7146</th>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>19</td>\n",
       "      <td>0.209381</td>\n",
       "      <td>1150</td>\n",
       "      <td>9211.04</td>\n",
       "      <td>-5.522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7147</th>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>20</td>\n",
       "      <td>0.177808</td>\n",
       "      <td>1060</td>\n",
       "      <td>9185.98</td>\n",
       "      <td>-5.600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7148</th>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>21</td>\n",
       "      <td>0.153912</td>\n",
       "      <td>960</td>\n",
       "      <td>9126.20</td>\n",
       "      <td>-22.674</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7149</th>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>22</td>\n",
       "      <td>0.138465</td>\n",
       "      <td>844</td>\n",
       "      <td>9122.69</td>\n",
       "      <td>-24.144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7150</th>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>23</td>\n",
       "      <td>0.192858</td>\n",
       "      <td>734</td>\n",
       "      <td>9140.85</td>\n",
       "      <td>-17.820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7151 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date2  hour  vader_sent_hourly mean  Daily Weight count    Close  \\\n",
       "0     2019-01-01     0                0.147142                 735  3700.31   \n",
       "1     2019-01-01     1                0.158979                 603  3689.69   \n",
       "2     2019-01-01     2                0.151551                 629  3690.00   \n",
       "3     2019-01-01     3                0.183226                 546  3693.13   \n",
       "4     2019-01-01     4                0.202897                 519  3692.71   \n",
       "...          ...   ...                     ...                 ...      ...   \n",
       "7146  2019-10-31    19                0.209381                1150  9211.04   \n",
       "7147  2019-10-31    20                0.177808                1060  9185.98   \n",
       "7148  2019-10-31    21                0.153912                 960  9126.20   \n",
       "7149  2019-10-31    22                0.138465                 844  9122.69   \n",
       "7150  2019-10-31    23                0.192858                 734  9140.85   \n",
       "\n",
       "      price dir  movement  \n",
       "0         0.000         0  \n",
       "1         3.538         1  \n",
       "2         3.656         1  \n",
       "3         1.340         1  \n",
       "4        -2.038         0  \n",
       "...         ...       ...  \n",
       "7146     -5.522         0  \n",
       "7147     -5.600         0  \n",
       "7148    -22.674         0  \n",
       "7149    -24.144         0  \n",
       "7150    -17.820         0  \n",
       "\n",
       "[7151 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.columns)\n",
    "data = data.filter(['date2','hour','vader_sent_hourly mean','Daily Weight count','Close','price dir','movement'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7151\n",
      "      vader_sent_hourly mean    Close  Daily Weight count  movement\n",
      "0                   0.147142  3700.31                 735         0\n",
      "1                   0.158979  3689.69                 603         1\n",
      "2                   0.151551  3690.00                 629         1\n",
      "3                   0.183226  3693.13                 546         1\n",
      "4                   0.202897  3692.71                 519         0\n",
      "...                      ...      ...                 ...       ...\n",
      "7146                0.209381  9211.04                1150         0\n",
      "7147                0.177808  9185.98                1060         0\n",
      "7148                0.153912  9126.20                 960         0\n",
      "7149                0.138465  9122.69                 844         0\n",
      "7150                0.192858  9140.85                 734         0\n",
      "\n",
      "[7151 rows x 4 columns]\n",
      "[[0.30218862 0.0315168  0.19933278 0.        ]\n",
      " [0.32328959 0.03051438 0.16263553 1.        ]\n",
      " [0.31004717 0.03054364 0.16986378 1.        ]\n",
      " ...\n",
      " [0.31425676 0.5436662  0.2618849  0.        ]\n",
      " [0.28671938 0.54333489 0.22963581 0.        ]\n",
      " [0.38368415 0.54504901 0.19905477 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "time_len = data.shape[0]\n",
    "print(time_len)\n",
    "x = data.filter(['vader_sent_hourly mean','Close','Daily Weight count',\"movement\"])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "xx = x.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(xx)\n",
    "#df = pd.DataFrame(x_scaled)\n",
    "print(x_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use series_to_supervised to get time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var0(t-2)  var1(t-2)  var2(t-2)  var3(t-2)  var0(t-1)  var1(t-1)  \\\n",
      "2   0.302189   0.031517   0.199333        0.0   0.323290   0.030514   \n",
      "3   0.323290   0.030514   0.162636        1.0   0.310047   0.030544   \n",
      "4   0.310047   0.030544   0.169864        1.0   0.366514   0.030839   \n",
      "5   0.366514   0.030839   0.146789        1.0   0.401580   0.030799   \n",
      "6   0.401580   0.030799   0.139283        0.0   0.277331   0.031482   \n",
      "\n",
      "   var2(t-1)  var3(t-1)  var3(t)  \n",
      "2   0.162636        1.0      1.0  \n",
      "3   0.169864        1.0      1.0  \n",
      "4   0.146789        1.0      0.0  \n",
      "5   0.139283        0.0      0.0  \n",
      "6   0.142341        0.0      1.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "# input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (df.columns[j], i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (df.columns[j])) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (df.columns[j], i)) for j in range(n_vars)]\n",
    "# put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    " \n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "xx[:,3] = encoder.fit_transform(xx[:,3])\n",
    "# ensure all data is float\n",
    "xx = xx.astype('float32')\n",
    "# normalize features\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(xx)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 2, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[8,9,10]], axis=1, inplace=True)\n",
    "print(reframed.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM MODEL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import reuters, imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, SimpleRNN, GRU, Dense, Dropout, Activation, Embedding, ConvLSTM2D,CuDNNLSTM,Bidirectional, Conv2D,Conv1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from keras import metrics as met2\n",
    "import math\n",
    "from numpy import concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split and reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7149, 9)\n",
      "(7149, 8) (7149,)\n",
      "(5719, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "labels = reframed.values[:,-1]\n",
    "#labels = labels.astype('int')\n",
    "print(reframed.shape)\n",
    "features = reframed.values[:,:8]\n",
    "print(features.shape,labels.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
    "x_train = x_train.reshape((x_train.shape[0], 2, 4))\n",
    "x_test = x_test.reshape((x_test.shape[0],2, 4))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yq/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/yq/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 5719 samples, validate on 1430 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.6542 - binary_accuracy: 0.6583 - val_loss: 0.6106 - val_binary_accuracy: 0.7329\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.5844 - binary_accuracy: 0.7272 - val_loss: 0.5453 - val_binary_accuracy: 0.7580\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.5546 - binary_accuracy: 0.7563 - val_loss: 0.5338 - val_binary_accuracy: 0.7755\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.5493 - binary_accuracy: 0.7615 - val_loss: 0.5312 - val_binary_accuracy: 0.7755\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.5486 - binary_accuracy: 0.7615 - val_loss: 0.5305 - val_binary_accuracy: 0.7755\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.5482 - binary_accuracy: 0.7615 - val_loss: 0.5300 - val_binary_accuracy: 0.7755\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.5471 - binary_accuracy: 0.7615 - val_loss: 0.5294 - val_binary_accuracy: 0.7755\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.5470 - binary_accuracy: 0.7615 - val_loss: 0.5293 - val_binary_accuracy: 0.7755\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.5480 - binary_accuracy: 0.7615 - val_loss: 0.5291 - val_binary_accuracy: 0.7755\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.5467 - binary_accuracy: 0.7615 - val_loss: 0.5290 - val_binary_accuracy: 0.7755\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.5460 - binary_accuracy: 0.7615 - val_loss: 0.5286 - val_binary_accuracy: 0.7755\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.5465 - binary_accuracy: 0.7615 - val_loss: 0.5286 - val_binary_accuracy: 0.7755\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.5472 - binary_accuracy: 0.7615 - val_loss: 0.5284 - val_binary_accuracy: 0.7755\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.5458 - binary_accuracy: 0.7615 - val_loss: 0.5283 - val_binary_accuracy: 0.7755\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.5461 - binary_accuracy: 0.7615 - val_loss: 0.5281 - val_binary_accuracy: 0.7755\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.5465 - binary_accuracy: 0.7615 - val_loss: 0.5282 - val_binary_accuracy: 0.7755\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.5463 - binary_accuracy: 0.7615 - val_loss: 0.5280 - val_binary_accuracy: 0.7755\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.5468 - binary_accuracy: 0.7615 - val_loss: 0.5280 - val_binary_accuracy: 0.7755\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.5461 - binary_accuracy: 0.7615 - val_loss: 0.5279 - val_binary_accuracy: 0.7755\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.5446 - binary_accuracy: 0.7615 - val_loss: 0.5277 - val_binary_accuracy: 0.7755\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.5458 - binary_accuracy: 0.7615 - val_loss: 0.5277 - val_binary_accuracy: 0.7755\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.5460 - binary_accuracy: 0.7615 - val_loss: 0.5276 - val_binary_accuracy: 0.7755\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.5461 - binary_accuracy: 0.7615 - val_loss: 0.5277 - val_binary_accuracy: 0.7755\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.5457 - binary_accuracy: 0.7615 - val_loss: 0.5274 - val_binary_accuracy: 0.7755\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.5457 - binary_accuracy: 0.7615 - val_loss: 0.5276 - val_binary_accuracy: 0.7755\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.5453 - binary_accuracy: 0.7615 - val_loss: 0.5273 - val_binary_accuracy: 0.7755\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.5451 - binary_accuracy: 0.7615 - val_loss: 0.5274 - val_binary_accuracy: 0.7755\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.5455 - binary_accuracy: 0.7615 - val_loss: 0.5273 - val_binary_accuracy: 0.7755\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.5460 - binary_accuracy: 0.7615 - val_loss: 0.5274 - val_binary_accuracy: 0.7755\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.5453 - binary_accuracy: 0.7615 - val_loss: 0.5273 - val_binary_accuracy: 0.7755\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.5458 - binary_accuracy: 0.7615 - val_loss: 0.5274 - val_binary_accuracy: 0.7755\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.5457 - binary_accuracy: 0.7615 - val_loss: 0.5274 - val_binary_accuracy: 0.7755\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.5457 - binary_accuracy: 0.7615 - val_loss: 0.5272 - val_binary_accuracy: 0.7755\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.5462 - binary_accuracy: 0.7615 - val_loss: 0.5272 - val_binary_accuracy: 0.7755\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.5453 - binary_accuracy: 0.7615 - val_loss: 0.5271 - val_binary_accuracy: 0.7755\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.5456 - binary_accuracy: 0.7615 - val_loss: 0.5271 - val_binary_accuracy: 0.7755\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.5440 - binary_accuracy: 0.7615 - val_loss: 0.5270 - val_binary_accuracy: 0.7755\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.5450 - binary_accuracy: 0.7615 - val_loss: 0.5271 - val_binary_accuracy: 0.7755\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.5452 - binary_accuracy: 0.7615 - val_loss: 0.5271 - val_binary_accuracy: 0.7755\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.5455 - binary_accuracy: 0.7615 - val_loss: 0.5272 - val_binary_accuracy: 0.7755\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.5445 - binary_accuracy: 0.7615 - val_loss: 0.5270 - val_binary_accuracy: 0.7755\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.5447 - binary_accuracy: 0.7615 - val_loss: 0.5270 - val_binary_accuracy: 0.7755\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.5453 - binary_accuracy: 0.7615 - val_loss: 0.5269 - val_binary_accuracy: 0.7755\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.5458 - binary_accuracy: 0.7615 - val_loss: 0.5271 - val_binary_accuracy: 0.7755\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.5454 - binary_accuracy: 0.7615 - val_loss: 0.5270 - val_binary_accuracy: 0.7755\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.5451 - binary_accuracy: 0.7615 - val_loss: 0.5269 - val_binary_accuracy: 0.7755\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.5445 - binary_accuracy: 0.7615 - val_loss: 0.5269 - val_binary_accuracy: 0.7755\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.5444 - binary_accuracy: 0.7615 - val_loss: 0.5267 - val_binary_accuracy: 0.7755\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.5449 - binary_accuracy: 0.7615 - val_loss: 0.5269 - val_binary_accuracy: 0.7755\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.5450 - binary_accuracy: 0.7615 - val_loss: 0.5268 - val_binary_accuracy: 0.7755\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_3 (Bidirection (None, 100)               22000     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 22,101\n",
      "Trainable params: 22,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# design network\n",
    "#for i in range(1,10):\n",
    "model = Sequential()\n",
    "#model.add(Conv2D(100, 2, activation='relu'))\n",
    "#model.add(SimpleRNN(32))\n",
    "model.add(Bidirectional(LSTM((50), input_shape=(x_train.shape[1], x_train.shape[2]))))\n",
    "#model.add(ConvLSTM2D(2,kernel_size = (3,3),input_shape =(None,x_train.shape[1], x_train.shape[2],1) ,padding='same', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=[met2.binary_accuracy], optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=100, validation_data=(x_test, y_test), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.415\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "\n",
    "#x_test = test_X.reshape((x_test.shape[0], x_test.shape[2]))\n",
    "yhat = model.predict(x_test)\n",
    "#print(yhat.score)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[507 167]\n",
      " [154 602]]\n",
      "1430/1430 [==============================] - 0s 11us/step\n",
      "Test score: 0.7755244970321655\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(yhat[0:90])\n",
    "yhat = yhat.astype(\"float64\")\n",
    "y2 = yhat\n",
    "for i in range(yhat.shape[0]):\n",
    "    if y2[i] >0.5:\n",
    "        y2[i] = 1\n",
    "    else:\n",
    "        y2[i] = 0\n",
    "matrix = metrics.confusion_matrix(y_test,yhat)\n",
    "#acc = met2.binary_accuracy(y_test,keras.backend.round(yhat),threshold=0.5)\n",
    "print(matrix)\n",
    "#print(acc)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=72, verbose=1)\n",
    "print('Test score:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
